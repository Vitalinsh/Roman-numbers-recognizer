{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_in_cloud = \"1Gl-YYH-1Rqrcx1htX1-6nqWDyqaRI0UT\"\n",
    "model_id_in_cloud = \"1ug2PVwrggSQ7ro2mjGhfXVaZ--j7kLBP\"\n",
    "\n",
    "main_dir = \".\"\n",
    "data_dir = os.path.join(main_dir, \"data\")\n",
    "dataset_zip_dir = os.path.join(data_dir, \"roman-numbers-dataset.zip\")\n",
    "dataset_dir = os.path.join(data_dir, \"roman-numbers-dataset\")\n",
    "\n",
    "saved_model_zip_dir = os.path.join(main_dir, \"saved_models.zip\")\n",
    "saved_model_dir = os.path.join(main_dir, \"saved_models\")\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "train_portion = 0.6\n",
    "test_portion = 0.2\n",
    "val_portion = 0.2\n",
    "\n",
    "img_height = 64\n",
    "img_width = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset...\n",
      "Downloading 1Gl-YYH-1Rqrcx1htX1-6nqWDyqaRI0UT into .\\data\\roman-numbers-dataset.zip... Done.\n",
      "Unzipping...Done.\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Downloading the dataset...\")\n",
    "    gdd.download_file_from_google_drive(\n",
    "        file_id=dataset_id_in_cloud,\n",
    "        dest_path=dataset_zip_dir,\n",
    "        unzip=True)\n",
    "    print(\"Completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(dataset_dir)\n",
    "n_classes = len(classes)\n",
    "print(n_classes)\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(dir_name, classes_list):\n",
    "    \"\"\"\n",
    "    Create folder for each class\n",
    "    \"\"\"\n",
    "    if os.path.exists(dir_name):\n",
    "        shutil.rmtree(dir_name)\n",
    "    os.makedirs(dir_name)\n",
    "    \n",
    "    for class_name in classes_list:   \n",
    "        os.makedirs(os.path.join(dir_name, class_name))\n",
    "        \n",
    "def resize_img(img_path, img_height, img_width):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((img_height, img_width))\n",
    "    img.save(img_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories(train_dir, classes)\n",
    "create_directories(val_dir, classes)\n",
    "create_directories(test_dir, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I :\n",
      "total number of imgs for class= 213\n",
      "number of imgs for train = 127\n",
      "number of imgs for valid = 42\n",
      "number of imgs for test = 44\n",
      "\n",
      " II :\n",
      "total number of imgs for class= 211\n",
      "number of imgs for train = 126\n",
      "number of imgs for valid = 42\n",
      "number of imgs for test = 43\n",
      "\n",
      " III :\n",
      "total number of imgs for class= 211\n",
      "number of imgs for train = 126\n",
      "number of imgs for valid = 42\n",
      "number of imgs for test = 43\n",
      "\n",
      " IV :\n",
      "total number of imgs for class= 206\n",
      "number of imgs for train = 123\n",
      "number of imgs for valid = 41\n",
      "number of imgs for test = 42\n",
      "\n",
      " V :\n",
      "total number of imgs for class= 204\n",
      "number of imgs for train = 122\n",
      "number of imgs for valid = 40\n",
      "number of imgs for test = 42\n",
      "\n",
      " VI :\n",
      "total number of imgs for class= 210\n",
      "number of imgs for train = 126\n",
      "number of imgs for valid = 42\n",
      "number of imgs for test = 42\n",
      "\n",
      " VII :\n",
      "total number of imgs for class= 207\n",
      "number of imgs for train = 124\n",
      "number of imgs for valid = 41\n",
      "number of imgs for test = 42\n",
      "\n",
      " VIII :\n",
      "total number of imgs for class= 194\n",
      "number of imgs for train = 116\n",
      "number of imgs for valid = 38\n",
      "number of imgs for test = 40\n",
      "\n",
      "Total train images = 990\n",
      "Total validation images = 328\n",
      "Total test images = 338\n"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "\n",
    "total_n_train = 0\n",
    "total_n_valid = 0\n",
    "total_n_test = 0\n",
    "\n",
    "for class_name in classes:\n",
    "    image_list = os.listdir(os.path.join(dataset_dir, class_name))\n",
    "    random.shuffle(image_list)\n",
    "    \n",
    "    n_train_img = int(len(image_list) * train_portion)\n",
    "    n_valid_img = int(len(image_list) * val_portion)\n",
    "    n_test_img = len(image_list) - n_train_img - n_valid_img\n",
    "    \n",
    "    train_list = image_list[: n_train_img]\n",
    "    valid_list = image_list[n_train_img: n_train_img + n_valid_img]\n",
    "    test_list = image_list[n_train_img + n_valid_img:]\n",
    "    \n",
    "    data_lists = [train_list, valid_list, test_list]\n",
    "    dirs_list = [train_dir, val_dir, test_dir]\n",
    "    \n",
    "    for i, data_list in enumerate(data_lists):\n",
    "        for img_name in data_list:\n",
    "            shutil.copy2(os.path.join(dataset_dir, class_name, img_name), \n",
    "                        os.path.join(dirs_list[i], class_name))\n",
    "            img_path = os.path.join(dirs_list[i], class_name, img_name)\n",
    "            resize_img(img_path, img_height, img_width)\n",
    "            \n",
    "    print(\"\\n\", class_name, \":\")\n",
    "    print(\"total number of imgs for class=\", len(image_list))\n",
    "    print(\"number of imgs for train =\", n_train_img)\n",
    "    print(\"number of imgs for valid =\", n_valid_img)\n",
    "    print(\"number of imgs for test =\", n_test_img)\n",
    "    \n",
    "    total_n_train += n_train_img\n",
    "    total_n_valid += n_valid_img\n",
    "    total_n_test += n_test_img\n",
    "    \n",
    "print(\"\\nTotal train images =\", total_n_train )\n",
    "print(\"Total validation images =\",total_n_valid)\n",
    "print(\"Total test images =\", total_n_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the tensorflow model...\n",
      "Downloading 1zMBeehEd0rVqe5MD6a9ct4cxW3YcuthQ into .\\saved_models.zip... Done.\n",
      "Unzipping...Done.\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    print(\"Downloading the tensorflow model...\")\n",
    "    gdd.download_file_from_google_drive(\n",
    "        file_id=model_id_in_cloud,\n",
    "        dest_path=saved_model_zip_dir,\n",
    "        unzip=True)\n",
    "    print(\"Completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
