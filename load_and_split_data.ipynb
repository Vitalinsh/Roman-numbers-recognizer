{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_in_cloud = \"1TZF0qVN1PojR5o_nPR_cl7T9sxH37iMY\"\n",
    "\n",
    "main_dir = \".\"\n",
    "data_dir = os.path.join(main_dir, \"data\")\n",
    "dataset_zip_dir = os.path.join(data_dir, \"roman-numbers-dataset.zip\")\n",
    "dataset_dir = os.path.join(data_dir, \"roman-numbers-dataset\")\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "train_portion = 0.6\n",
    "test_portion = 0.2\n",
    "val_portion = 0.2\n",
    "\n",
    "img_height = 64\n",
    "img_width = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Downloading the dataset...\")\n",
    "    gdd.download_file_from_google_drive(\n",
    "        file_id=dataset_id_in_cloud,\n",
    "        dest_path=dataset_zip_dir,\n",
    "        unzip=True)\n",
    "    print(\"Completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['II', 'IV', 'VI', 'V', 'VIII', 'VII', 'III', 'I']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(dataset_dir)\n",
    "n_classes = len(classes)\n",
    "print(n_classes)\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(dir_name, classes_list):\n",
    "    \"\"\"\n",
    "    Create folder for each class\n",
    "    \"\"\"\n",
    "    if os.path.exists(dir_name):\n",
    "        shutil.rmtree(dir_name)\n",
    "    os.makedirs(dir_name)\n",
    "    \n",
    "    for class_name in classes_list:   \n",
    "        os.makedirs(os.path.join(dir_name, class_name))\n",
    "        \n",
    "def resize_img(img_path, img_height, img_width):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    cv2.imwrite(img_path, img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories(train_dir, classes)\n",
    "create_directories(val_dir, classes)\n",
    "create_directories(test_dir, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " II :\n",
      "total number of imgs = 198\n",
      "number of imgs for train = 118\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 41\n",
      "\n",
      " IV :\n",
      "total number of imgs = 197\n",
      "number of imgs for train = 118\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 40\n",
      "\n",
      " VI :\n",
      "total number of imgs = 195\n",
      "number of imgs for train = 117\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 39\n",
      "\n",
      " V :\n",
      "total number of imgs = 193\n",
      "number of imgs for train = 115\n",
      "number of imgs for valid = 38\n",
      "number of imgs for test = 40\n",
      "\n",
      " VIII :\n",
      "total number of imgs = 197\n",
      "number of imgs for train = 118\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 40\n",
      "\n",
      " VII :\n",
      "total number of imgs = 198\n",
      "number of imgs for train = 118\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 41\n",
      "\n",
      " III :\n",
      "total number of imgs = 195\n",
      "number of imgs for train = 117\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 39\n",
      "\n",
      " I :\n",
      "total number of imgs = 199\n",
      "number of imgs for train = 119\n",
      "number of imgs for valid = 39\n",
      "number of imgs for test = 41\n"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "\n",
    "for class_name in classes:\n",
    "    image_list = os.listdir(os.path.join(dataset_dir, class_name))\n",
    "    random.shuffle(image_list)\n",
    "    \n",
    "    n_train_img = int(len(image_list) * train_portion)\n",
    "    n_valid_img = int(len(image_list) * val_portion)\n",
    "    n_test_img = len(image_list) - n_train_img - n_valid_img\n",
    "    \n",
    "    train_list = image_list[: n_train_img]\n",
    "    valid_list = image_list[n_train_img: n_train_img + n_valid_img]\n",
    "    test_list = image_list[n_train_img + n_valid_img:]\n",
    "    \n",
    "    data_lists = [train_list, valid_list, test_list]\n",
    "    dirs_list = [train_dir, val_dir, test_dir]\n",
    "    \n",
    "    for i, data_list in enumerate(data_lists):\n",
    "        for img_name in data_list:\n",
    "            shutil.copy2(os.path.join(dataset_dir, class_name, img_name), \n",
    "                        os.path.join(dirs_list[i], class_name))\n",
    "            img_path = os.path.join(dirs_list[i], class_name, img_name)\n",
    "            resize_img(img_path, img_height, img_width)\n",
    "            \n",
    "    print(\"\\n\", class_name, \":\")\n",
    "    print(\"total number of imgs =\", len(image_list))\n",
    "    print(\"number of imgs for train =\", n_train_img)\n",
    "    print(\"number of imgs for valid =\", n_valid_img)\n",
    "    print(\"number of imgs for test =\", n_test_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    X = list()\n",
    "    y = list()\n",
    "    \n",
    "    for folder in classes:\n",
    "        path = '{}/{}/'.format(train_dir, folder)\n",
    "        files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "        for filename in files:\n",
    "            img = Image.open(path + filename)\n",
    "            img = img.resize((64,64))\n",
    "            img = np.array(img)\n",
    "            X.append(img)\n",
    "            y.append(folder)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(images):\n",
    "    original_images = images.copy()\n",
    "    result = list()\n",
    "\n",
    "    transformations = [\n",
    "        iaa.Fliplr(1),\n",
    "        iaa.Flipud(1),\n",
    "        iaa.Affine(rotate=10),\n",
    "        iaa.Affine(rotate=22),\n",
    "        iaa.Affine(rotate=45),\n",
    "        iaa.Affine(rotate=67),\n",
    "        iaa.Affine(rotate=90),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
    "        iaa.Dropout(p=(0, 0.2)),\n",
    "        iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "        iaa.CropAndPad(percent=(-0.25, 0.25))\n",
    "    ]\n",
    "\n",
    "    for transform in transformations:\n",
    "        aug_images = transform.augment_images(original_images)\n",
    "        result.extend(aug_images)\n",
    "    \n",
    "    return images + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_images = augmentation(X)\n",
    "labels = y * (len(aug_images) // len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
