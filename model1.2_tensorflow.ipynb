{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data_to_mem, augmentation, show_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\".\", \"data\", \"train\")\n",
    "valid_path = os.path.join(\".\", \"data\", \"val\")\n",
    "test_path = os.path.join(\".\", \"data\", \"test\")\n",
    "\n",
    "classes = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\"]\n",
    "class_mapping = {\"I\": 0, \"II\": 1, \"III\": 2, \"IV\": 3,\n",
    "                 \"V\": 4, \"VI\": 5, \"VII\": 6, \"VIII\":7}\n",
    "n_classes = len(classes)\n",
    "\n",
    "def class_to_number(n):\n",
    "    return class_mapping[n]\n",
    "\n",
    "img_rows, img_cols, n_channels = 64, 64, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data_to_mem(train_path, classes)\n",
    "X_valid, y_valid = load_data_to_mem(valid_path, classes)\n",
    "X_test, y_test = load_data_to_mem(test_path, classes)\n",
    "\n",
    "X_train, y_train = augmentation(X_train, y_train, n_transform=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_valid = np.array(X_valid, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# expand dimensions for CNN\n",
    "X_train = np.expand_dims(X_train, axis=3) \n",
    "X_valid = np.expand_dims(X_valid, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "y_train = np.array(list(map(class_to_number, y_train)))\n",
    "y_valid = np.array(list(map(class_to_number, y_valid)))\n",
    "y_test = np.array(list(map(class_to_number, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check shapes: \n",
      "X_train = (60390, 64, 64, 1)  Y_train = 60390\n",
      "X_valid = (328, 64, 64, 1)  Y_valid = 328\n",
      "X_test = (338, 64, 64, 1)  Y_test = 338\n"
     ]
    }
   ],
   "source": [
    "print(\"Check shapes: \")\n",
    "print(\"X_train =\", X_train.shape, \" Y_train =\", len(y_train))\n",
    "print(\"X_valid =\", X_valid.shape, \" Y_valid =\", len(y_valid))\n",
    "print(\"X_test =\", X_test.shape, \" Y_test =\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "#parameters of convolutional layer\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "conv3_fmaps = 64\n",
    "conv3_ksize = 5\n",
    "conv3_stride = 2\n",
    "conv3_pad = \"SAME\"\n",
    "\n",
    "#parameters of pooling layer\n",
    "pool2_fmaps = conv2_fmaps\n",
    "#parameters of fully connected network and outputs\n",
    "n_dense1 = 256\n",
    "n_outputs = 8\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, img_rows, img_cols, n_channels], name = \"X\")\n",
    "y = tf.placeholder(tf.int32, shape = [None], name = \"y\")\n",
    "    \n",
    "conv1 = tf.layers.conv2d(X, filters=conv1_fmaps, kernel_size = conv1_ksize,\n",
    "                         strides = conv1_stride, padding=conv1_pad,\n",
    "                         activation = tf.nn.relu, name=\"conv_1\")\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                       padding=\"VALID\", name=\"pool_1\")\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv_2\")\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                       padding=\"VALID\", name=\"pool_2\")\n",
    "    \n",
    "conv3 = tf.layers.conv2d(pool2, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=conv3_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv_3\")\n",
    "pool3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1],  strides=[1, 2, 2, 1],\n",
    "                       padding=\"VALID\", name=\"pool_3\")\n",
    "\n",
    "flat1 = tf.layers.flatten(pool3, name=\"flatten_1\")\n",
    "dense1 = tf.layers.dense(flat1, n_dense1, activation=tf.nn.relu,\n",
    "                          name = \"dense_1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(dense1, n_outputs, name = \"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN. \n",
    "\n",
    "Skip next 2 cells if you want to test saved model. \n",
    "\n",
    "Training CNN has taken about 30 min with nVidia 940mx GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_score = -9999999\n",
    "early_stop_patience = 5\n",
    "last_score = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train accuracy: 0.453125 Val accuracy: 0.3628049\n",
      "Model saved.\n",
      "Epoch: 2 Train accuracy: 0.6875 Val accuracy: 0.6097561\n",
      "Model saved.\n",
      "Epoch: 3 Train accuracy: 0.78125 Val accuracy: 0.6707317\n",
      "Model saved.\n",
      "Epoch: 4 Train accuracy: 0.765625 Val accuracy: 0.7012195\n",
      "Model saved.\n",
      "Epoch: 5 Train accuracy: 0.796875 Val accuracy: 0.69512194\n",
      "Epoch: 6 Train accuracy: 0.828125 Val accuracy: 0.72865856\n",
      "Model saved.\n",
      "Epoch: 7 Train accuracy: 0.765625 Val accuracy: 0.7134146\n",
      "Epoch: 8 Train accuracy: 0.890625 Val accuracy: 0.722561\n",
      "Epoch: 9 Train accuracy: 0.890625 Val accuracy: 0.7530488\n",
      "Model saved.\n",
      "Epoch: 10 Train accuracy: 0.875 Val accuracy: 0.76829267\n",
      "Model saved.\n",
      "Epoch: 11 Train accuracy: 0.984375 Val accuracy: 0.72865856\n",
      "Epoch: 12 Train accuracy: 0.953125 Val accuracy: 0.75\n",
      "Epoch: 13 Train accuracy: 0.96875 Val accuracy: 0.7652439\n",
      "Epoch: 14 Train accuracy: 0.9375 Val accuracy: 0.7743902\n",
      "Model saved.\n",
      "Epoch: 15 Train accuracy: 0.96875 Val accuracy: 0.7835366\n",
      "Model saved.\n",
      "Wall time: 16min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration * batch_size: iteration * batch_size + batch_size]\n",
    "            y_batch = y_train[iteration * batch_size: iteration * batch_size + batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(\"Epoch:\", epoch+1, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_valid)\n",
    "        # save only best model\n",
    "        if acc_valid > best_val_score:\n",
    "            best_val_score = acc_valid\n",
    "            save_path = saver.save(sess, \"./saved_models/model1.3_tf\")\n",
    "            print(\"Model saved.\")\n",
    "        # early stopping\n",
    "        if acc_valid < last_score:\n",
    "            early_stop_patience -= 1\n",
    "        if early_stop_patience <= 0:\n",
    "            break  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_test, y_test):\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init) \n",
    "        saver = tf.train.import_meta_graph('saved_models/model1.3_tf.meta')\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('./saved_models/'))\n",
    "        pred = sess.run([accuracy, loss], feed_dict={X: X_test, y: y_test})\n",
    "        print(\"Test accuracy =\", pred[0])\n",
    "        print(\"Test loss =\", pred[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models/model1.3_tf\n",
      "Test accuracy = 0.75147927\n",
      "Test loss = 1.1124166\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
